---
title: "macOSネイティブでコンテナイメージをクロスコンパイルする"
emoji: "🐋"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["nix", "container", "docker"]
published: true
---

## はじめに

macOSでコンテナ開発を行うとき、特にApple Silicon（M1/M2）搭載のMacを使用している場合、マルチアーキテクチャ対応のコンテナイメージを作成するには課題がある。

macOSでのコンテナ実行環境は、主に複数の仮想化技術に依存している。Docker Desktopは従来はHyperKit（macOSのHypervisor.framework上に構築）を利用していたが、現在ではApple Silicon向けにVirtualization Frameworkも採用し、LinuxKit VMを使用してコンテナを実行している。Rancher DesktopはLima VMを活用しており、内部的にはQEMUを使用している。最近のバージョンではApple Silicon向けにVirtualization Frameworkのサポートも追加された。Limaは「macOS向けのWSL2」とも呼ばれ、QEMUを利用して軽量Linuxマシンを実行する仕組みである。

これらの仮想化技術は便利だが、特に異なるアーキテクチャ（例：Intel/AMD向けのx86_64）向けのコンテナを実行・ビルドする場合、エミュレーションによるオーバーヘッドが発生し、ビルド時間の長さやリソース消費の問題が生じる。さらに、macOSでは仮想環境をネストして実行することが難しいという技術的制約があり、仮想化環境内で別の仮想化環境を実行する必要がある場合に問題となる。

この記事では、Nixを活用してmacOS上で直接異なるアーキテクチャ（aarch64-linuxやx86_64-linux）向けのコンテナイメージをクロスコンパイルする方法を紹介する。この方法を使うことで、仮想化やエミュレーションを使わずに、高速かつ効率的にマルチアーキテクチャのコンテナイメージをビルドすることができる。なお、この手法はmacOSに限らず、x86_64-linuxからaarch64-linux向けのクロスコンパイルなど、他の環境の組み合わせでも適用可能である。例えばCI環境でx86_64-linuxのランナーしか利用できない場合でも、aarch64-linux向けのコンテナイメージを効率的に生成できる。

この記事は、macOS（特にApple Silicon搭載機）でコンテナ開発を行っている方、ビルドプロセスを高速化したい方、Nixに興味がある方、そして複数アーキテクチャ向けのイメージを効率的に作成したい方に役立つ内容となっている。実際の実装例として[cross-compiling-container-example](https://github.com/natsukium/cross-compiling-container-example)リポジトリのコードをベースに、実装方法と使い方を詳しく説明していく。

## 前提条件

この記事の内容を実践するには、いくつかのツールが必要である。まず、macOSにNixをインストールする必要があり、これは公式サイトの手順に従って`sh <(curl -L https://nixos.org/nix/install)`コマンドで行える。次に、コンテナイメージをロードして実行するためにDockerが必要で、Docker Desktop for MacやRancher Desktopなどの選択肢がある。さらに、基本的なNixの知識、特にflakeや設定ファイルの基本を理解していると作業がスムーズに進む。これらのツールをインストールしたら、次のセクションで実際の実装に進むことができる。

## OCIコンテナイメージの理解

まず最初に、クロスコンパイルによるコンテナイメージ生成を理解するために、コンテナイメージ自体の構造と仕様について把握する必要がある。

### コンテナイメージとは

コンテナイメージとは、アプリケーションとその実行に必要な依存関係（ライブラリ、バイナリ、設定ファイルなど）をパッケージ化した自己完結型のアーティファクトである。これを使用することで、開発環境から本番環境まで一貫した実行環境を確保でき、「開発環境では動くのに本番環境では動かない」といった問題を軽減できる。

### OCIイメージ仕様の概要

Open Container Initiative (OCI) はコンテナフォーマットやランタイムに関するオープンな業界標準を定義している組織で、Docker、Kubernetes、Podman、Containerdなど様々なコンテナ技術間で共通のイメージフォーマットを標準化している。

OCIイメージの主な構成要素は以下の通りである：

1. **イメージマニフェスト**: イメージの内容や依存関係に関するメタデータを含む
2. **設定（Configuration）**: イメージの実行方法やレイヤーの順序を定義する
3. **ファイルシステムレイヤー**: 実際のファイル内容が含まれる階層構造
4. **イメージインデックス（オプション）**: 複数のマニフェストへの参照、アーキテクチャごとの異なる実装など

コンテナイメージはレイヤー構造を持ち、各レイヤーは前のレイヤーからの変更（ファイルの追加、修正、削除）を表している。この構造により、レイヤーを効率的に共有し、イメージ全体のサイズを削減できる。

### Nixによるコンテナイメージ生成

Nixは、関数型パッケージマネージャとして、Dockerデーモンなどの外部ツールに依存せずに、純粋に関数型プログラミングのアプローチでOCI仕様準拠のコンテナイメージを生成できる。これは`dockerTools.buildImage`関数によって実現される。

#### イメージ生成の内部メカニズム

`buildImage`関数の主な処理フローは以下の通りである：

1. **ルートファイルシステムの構築**:
   - 指定された`contents`（アプリケーションやライブラリ）からルートファイルシステム構造を作成
   - 依存関係を再帰的に解決し、必要なバイナリやライブラリを収集

2. **イメージレイヤーの作成**:
   - ルートファイルシステムの内容をtarファイルにアーカイブ
   - レイヤーのハッシュ値（SHA256）を計算して一意の識別子とする
   - レイヤーメタデータを生成（サイズ、作成日時など）

3. **イメージ設定（Configuration）の生成**:
   - OCIイメージ仕様に準拠したJSONオブジェクトを作成
   - アーキテクチャ情報（例："arm64"や"amd64"）を含める
   - ユーザー指定の設定（Cmd, ExposedPortsなど）を追加
   - レイヤーのハッシュリストを記録

4. **イメージマニフェストの作成**:
   - レイヤーと設定へのリファレンスを含むマニフェストJSONを生成
   - OCIバージョンやメディアタイプなどのメタデータを付加

5. **最終イメージの組み立て**:
   - マニフェスト、設定、レイヤーを含むOCI標準形式のtarアーカイブを作成
   - Docker互換フォーマットで出力

Nixを使ったコンテナイメージのビルドは、以下のような特徴を持つ：

1. **再現性**: 同じコードからは常に同じイメージが生成される
2. **最小限のサイズ**: 必要なファイルのみを含むため、イメージが小さい
3. **宣言的な定義**: イメージの内容を宣言的に定義できる
4. **依存関係の明示**: 全ての依存関係が明示的に指定される

## クロスコンパイルとは何か？

OCIコンテナイメージの基本を理解したところで、次にクロスコンパイルの概念を見ていく。クロスコンパイルとは、あるプラットフォーム（ホスト環境）で別のプラットフォーム（ターゲット環境）向けのコードをコンパイルすることである。例えば、macOS（aarch64-darwin）上でLinux（x86_64-linux）向けのバイナリを生成することが可能になる。これは特にコンテナイメージをビルドする際に非常に有用な技術である。

### 従来のアプローチと課題

従来、macOSでx86_64-linux向けのコンテナイメージをビルドする場合、いくつかの方法が用いられてきた。最も一般的なのはエミュレーション（QEMU）を使用する方法で、Docker Buildxを使用してQEMUによるエミュレーションでビルドを行う。これは`docker buildx build --platform linux/amd64,linux/arm64 -t myapp:latest .`のようなコマンドで実行できるが、エミュレーションによるパフォーマンスの低下やビルド時間の長さが問題となる。

また、クラウドCI/CDサービスやリモートのLinuxマシンを利用してビルドするリモートビルド方式も存在するが、ネットワーク依存やセットアップの複雑さが課題となる。さらに、仮想マシンでLinuxを実行し、その中でビルドするネイティブLinux環境アプローチもあるが、これはオーバーヘッドが大きく、リソース消費が激しいという問題がある。

これらの従来手法は、特に開発の反復サイクルを頻繁に行う場合には効率が悪く、開発生産性に影響を与える。さらに、先述したように、macOSでは仮想化環境をネストすることが難しいため、コンテナ内でさらに仮想化やエミュレーションを行う構成が必要な場合に技術的な制約に直面することがある。

## クロスコンパイルの基礎とNixによる実装

クロスコンパイルを理解するためには、まず基本的な概念を把握する必要がある。クロスコンパイルでは、以下の3つのプラットフォームが重要な役割を果たす。

1. **ビルドプラットフォーム（build platform）**: コンパイラが実行される環境
2. **ホストプラットフォーム（host platform）**: コンパイルされたプログラムが実行される環境
3. **ターゲットプラットフォーム（target platform）**: コンパイラを構築する場合にのみ関連する概念

通常のアプリケーション開発では、ターゲットプラットフォームはホストプラットフォームと同一と見なせるため、主にビルドプラットフォームとホストプラットフォームの関係に焦点を当てる。

### ターゲットトリプルとアーキテクチャの指定

クロスコンパイルにおいて、ターゲットとなるシステムは「ターゲットトリプル」と呼ばれる形式で指定される。これはLLVMと同じ形式を使用し、基本的に `<arch><sub>-<vendor>-<sys>-<env>` の形式となる。例えば：

- `x86_64-unknown-linux-gnu`: 64ビットLinuxマシン（GNU C ライブラリ使用）
- `aarch64-apple-darwin`: Apple Silicon搭載Mac
- `arm-unknown-linux-musleabihf`: ARMプロセッサ搭載Linux（musl libc使用）

各言語やツールチェーンは、これらのターゲットトリプルをサポートするための仕組みを持っている。

### Nixによるクロスコンパイルの仕組み

Nixは宣言的なパッケージマネージャとして、クロスコンパイルに対して特に強力なサポートを提供している。Nixpkgsは、クロスコンパイルのために主に2つの重要なパラメータを扱う：

- **localSystem**: ビルドが行われるシステム（ビルドプラットフォーム）
- **crossSystem**: 結果のバイナリが実行されるシステム（ホストプラットフォーム）

これらのパラメータが適切に設定されると、Nixは自動的に正しいクロスコンパイルツールチェーンとライブラリを用意する。

#### Nixでのクロスコンパイル方法

Nixでクロスコンパイルを行うには、いくつかの方法がある：

1. **pkgsCrossの使用**: Nixpkgsには事前設定されたクロスコンパイルターゲットのセットが含まれており、これを`pkgsCross`として利用できる。

```nix
let 
  pkgs = import <nixpkgs> { localSystem = "x86_64-linux"; };
in 
  pkgs.pkgsCross.aarch64-multiplatform.hello
```

2. **crossSystemの直接設定**: パッケージをインポートする際に`crossSystem`を直接設定することもできる。

```nix
let 
  pkgs = import <nixpkgs> { 
    # buildPlatform
    localSystem = "x86_64-linux"; 
    # hostPlatform
    crossSystem = "aarch64-linux"; 
  };
in 
  pkgs.hello
```

3. **examples.nixの使用**: Nixpkgsで定義された例のプラットフォームを参照することも可能。

```nix
let 
  lib = import <nixpkgs/lib>;
  pkgs = import <nixpkgs> {
    crossSystem = lib.systems.examples.aarch64-multiplatform;
  };
in 
  pkgs.hello
```

### クロスコンパイル用flake.nixの構造

典型的なクロスコンパイル用のflake.nixには、以下のような構造が含まれる。まず、必要な入力（inputs）として、nixpkgsとflake-utilsを指定する。次に、outputs部分で各システム向けの設定を定義する。この中で、ターゲットシステム用のパッケージセットとしてpkgsCrossを設定し、aarch64-linuxやx86_64-linux向けのクロスコンパイル環境を準備する。また、buildForTargetのような関数を定義して、指定したターゲット向けにビルドを行うロジックを実装する。

```nix
{
  inputs = {
    nixpkgs.url = "github:NixOS/nixpkgs/nixos-unstable";
    flake-utils.url = "github:numtide/flake-utils";
  };

  outputs = { self, nixpkgs, flake-utils }:
    flake-utils.lib.eachDefaultSystem (system:
      let
        pkgs = nixpkgs.legacyPackages.${system};
        
        # ターゲットシステム用のパッケージセット
        pkgsCross = {
          aarch64-linux = pkgs.pkgsCross.aarch64-multiplatform;
          x86_64-linux = pkgs.pkgsCross.gnu64;
        };
        
        # クロスコンパイル関数
        buildForTarget = target: ...
        
      in {
        packages = {
          aarch64-linux = buildForTarget "aarch64-linux";
          x86_64-linux = buildForTarget "x86_64-linux";
          default = self.packages.${system}.aarch64-linux;
        };
      }
    );
}
```

この構造により、単一の設定ファイルから様々なターゲットアーキテクチャ向けのビルドを行うことができる。これは、CI環境でのビルドの一貫性を確保するのにも役立つ。例えば、x86_64-linuxのCI環境からaarch64-linux向けのコンテナイメージをビルドする際にも、同じ設定ファイルを使用できる。

### クロスコンパイルの依存関係管理

クロスコンパイルにおいては、「ビルド時依存関係」と「実行時依存関係」を区別することが重要である：

- **ビルド時依存関係**: クロスコンパイルを行うコンピュータ上で実行されるツール
- **実行時依存関係**: ターゲットとするコンピュータ上で実行されるライブラリやツール

Nixpkgsでは、ビルド時依存関係は`nativeBuildInputs`に、実行時依存関係は`buildInputs`に配置される。この区別はネイティブコンパイルでは効果がないが、クロスコンパイルでは正しく動作するために不可欠である。

### Nixによるクロスコンパイルコンテナイメージの生成

Nixは、クロスコンパイルとコンテナイメージ生成を組み合わせることで、特に強力なワークフローを実現する。クロスコンパイル時に重要なのは、Nixが`crossSystem`の指定に基づいて、自動的にターゲットアーキテクチャ向けのパッケージとバイナリを選択する点である。例えば、x86_64-linuxをターゲットとする場合：

```nix
pkgs = import nixpkgs { 
  system = "aarch64-darwin";  # ローカルシステム（ビルド環境）
  crossSystem = "x86_64-linux"; # ターゲットシステム
};
```

このとき、`pkgs.hello`はx86_64-linux向けにビルドされ、イメージに含まれるバイナリもx86_64-linux用になる。

##### アーキテクチャ情報の埋め込み

OCIイメージの設定ファイルには、対象アーキテクチャ情報が含まれている。Nixは`buildImage`関数内部で以下のようなアーキテクチャ情報を設定する：

```json
{
  "architecture": "amd64",  // または "arm64"など
  "os": "linux",
  "config": {
    // ユーザー指定の設定
  },
  "rootfs": {
    "type": "layers",
    "diff_ids": [
      "sha256:..."  // レイヤーのハッシュ
    ]
  }
}
```

##### ホストとターゲットの分離

Nixの強みは、ビルド環境（ホスト）とターゲット環境を明確に分離できる点にある。例えば、

```nix
pkgs.dockerTools.buildImage {
  name = "web-server";
  tag = targetArch;
  
  contents = [
    app  // クロスコンパイルされたアプリケーション
    pkgs.coreutils  // ターゲットアーキテクチャ向けのcoreutils
  ];
  
  config = {
    Cmd = [ "${app}/bin/web-server" ];
    ExposedPorts = {
      "7878/tcp" = {};
    };
  };
}
```

上記の`app`や`pkgs.coreutils`は、すでにクロスコンパイル設定に基づいたターゲットアーキテクチャ向けにビルドされている。Nixはこれらのコンポーネントを組み合わせて、ホストシステムとは異なるアーキテクチャ向けのイメージを生成する。

この仕組みにより、macOS上でLinux向けのコンテナイメージを、エミュレーションなしに直接ビルドすることが可能になっている。

## 各言語のクロスコンパイル

クロスコンパイルは、C/C++、Rust、GoなどさまざまなプログラミングCで異なるアプローチが必要になる。ここでは、主要な言語でのクロスコンパイル手順を比較し、それぞれの特徴を説明する。

### C/C++でのクロスコンパイル

C/C++は長い歴史を持ち、クロスコンパイルの手法も確立されている。C/C++のクロスコンパイルには以下の要素が必要になる：

1. **クロスコンパイラ**: ターゲットアーキテクチャ向けのGCCやClangなどのコンパイラ
2. **ターゲットライブラリ**: ターゲットシステム向けの標準ライブラリ（glibc、musl等）
3. **ヘッダファイル**: ターゲットシステム向けの開発ヘッダ

#### GCCによるクロスコンパイル手順

Linuxシステムでは、クロスコンパイル用のGCCを以下のように使用できる：

1. クロスコンパイラのインストール：
   ```bash
   # Debian/Ubuntuの場合
   apt-get install gcc-aarch64-linux-gnu
   # または
   apt-get install crossbuild-essential-arm64
   ```

2. ターゲットを指定してコンパイル：
   ```bash
   aarch64-linux-gnu-gcc hello.c -o hello
   ```

Macでは、Homebrewを使ってクロスコンパイラをインストールする方法もある：
```bash
brew install arm-linux-gnueabihf-binutils
```

#### Clangによるクロスコンパイル

Clangはデフォルトでクロスコンパイル機能を持っており、対象アーキテクチャを指定するだけでクロスコンパイルが可能になる：

```bash
clang --target=aarch64-linux-gnu -o hello hello.c
```

ただし、標準ライブラリやヘッダファイルは別途用意する必要がある。sysrootオプションを使用して、ターゲットシステムのルートディレクトリを指定する：

```bash
clang --target=aarch64-linux-gnu --sysroot=/path/to/aarch64-sysroot -o hello hello.c
```

複雑なプロジェクトでは、CMakeを使用してクロスコンパイル設定を管理することも多い：

```bash
cmake -DCMAKE_TOOLCHAIN_FILE=aarch64-toolchain.cmake ..
```

ここで、`aarch64-toolchain.cmake`はクロスコンパイル用の設定ファイルである。

### Rustでのクロスコンパイル

Rustは最初からクロスコンパイルを念頭に置いて設計されており、比較的容易にクロスコンパイルを行うことができる。Rustのクロスコンパイルには以下の手順が必要となる：

1. **ターゲットの追加**: rustupを使用してターゲットアーキテクチャの標準ライブラリをインストールする
   ```bash
   rustup target add aarch64-unknown-linux-gnu
   ```

2. **リンカの設定**: `.cargo/config.toml`ファイルでターゲットごとのリンカを指定する
   ```toml
   [target.aarch64-unknown-linux-gnu]
   linker = "aarch64-linux-gnu-gcc"
   ```

3. **クロスコンパイルの実行**: ターゲットを指定してcargoコマンドを実行する
   ```bash
   cargo build --target aarch64-unknown-linux-gnu --release
   ```

Rustは多くのターゲットをサポートしており、以下のコマンドで利用可能なターゲットの一覧を確認できる：
```bash
rustc --print target-list
```

Rustでのクロスコンパイルでは、ターゲットシステム向けの依存ライブラリが必要な場合がある。例えば、OpenSSLなどのネイティブライブラリに依存するクレートをクロスコンパイルする場合、対応するライブラリをターゲットシステム向けにビルドするか、代替の純Rust実装を使用する必要がある。

Rustでは、`no_std`属性を使用して標準ライブラリに依存しないコードを書くことも可能で、これによりさらに多くのプラットフォームをターゲットにできる。特に組み込みシステム向けの開発で役立つアプローチである。

## 実装例：Nixを使ったクロスコンパイルコンテナの構築

ここまでの理論的な説明を踏まえて、実際の実装例を見ていこう。この記事全体で参照している[cross-compiling-container-example](https://github.com/natsukium/cross-compiling-container-example)リポジトリでは、シンプルなRust製Webサーバーを異なるアーキテクチャ向けにクロスコンパイルし、コンテナイメージとして提供する方法を示している。

### プロジェクト構成

サンプルプロジェクトの構成はシンプルだが、Nixによるクロスコンパイルの核心要素を全て含んでいる。リポジトリの主要なファイルは以下のとおりである：

```
.
├── flake.nix           # Nixビルド設定の中心ファイル
├── flake.lock          # 依存関係のロックファイル
├── hello.html          # Webサーバーが提供するHTMLファイル
├── 404.html            # エラーページ用HTMLファイル
└── src                 # Rustアプリケーションのソースコード
    ├── Cargo.toml      # Rustプロジェクト設定
    └── main.rs         # Webサーバーの実装
```

この構成は最小限ながらも、実際のプロジェクトでのクロスコンパイルパイプラインを理解するのに十分な要素を持っている。特に`flake.nix`ファイルは、クロスコンパイルとコンテナイメージ生成の仕組みを定義する中心的な役割を果たしている。

### flake.nixの構造と役割

`flake.nix`はNixによるクロスコンパイルの核心部分である。[リポジトリのflake.nix](https://github.com/natsukium/cross-compiling-container-example/blob/main/flake.nix)を見ると、その構造は以下のようになっている：

```nix
{
  description = "Example of cross-compiling container images";

  inputs.nixpkgs.url = "github:nixos/nixpkgs?ref=nixpkgs-unstable";

  outputs =
    inputs:
    let
      pkgs = import inputs.nixpkgs { system = "aarch64-darwin"; };
    in
    {
      packages.aarch64-darwin =
        let
          packageFor =
            pkgs:
            let
              inherit (pkgs) lib rustPlatform;
            in
            rustPlatform.buildRustPackage {
              pname = "web-server";
              version = "0.1.0";
              src = lib.cleanSource ./.;
              useFetchCargoVendor = true;
              cargoHash="sha256-LjIJYTE1EKNkzG5K4sQrjJ4TDbefId0vUH6qAOmnaj4=";
            };

          containerFor =
            pkgs:
            pkgs.dockerTools.buildImage {
              name = "web-server";
              tag = pkgs.hostPlatform.system;
              copyToRoot = [ ./. ];
              config = {
                Cmd = "${packageFor pkgs}/bin/web-server";
              };
            };
        in
        {
          default = packageFor pkgs;
          aarch64-container = containerFor pkgs.pkgsCross.aarch64-multiplatform-musl;
          x86_64-container = containerFor pkgs.pkgsCross.musl64;
        };

      devShells.aarch64-darwin.default = pkgs.mkShell {
        packages = with pkgs; [ cargo ];
      };
    };
}
```

このファイルは大きく分けて3つの主要部分から構成されている：

1. **inputs**: 必要なデータソースの定義。ここでは最新版のNixpkgsを参照している。
2. **let束縛**: ローカルシステム（この例ではaarch64-darwin）のパッケージセットを定義。
3. **outputs**: ビルド成果物の定義。この中に以下の重要な関数がある：
   - `packageFor`: Rustパッケージをビルドするための関数
   - `containerFor`: コンテナイメージを生成するための関数

特に注目すべき点は、`aarch64-container`と`x86_64-container`という二つのパッケージ定義で、これらはそれぞれ対応するアーキテクチャ向けのクロスコンパイル設定を使用している：

```nix
aarch64-container = containerFor pkgs.pkgsCross.aarch64-multiplatform-musl;
x86_64-container = containerFor pkgs.pkgsCross.musl64;
```

`pkgs.pkgsCross.aarch64-multiplatform-musl`は、aarch64（ARM64）アーキテクチャ向けのmuslライブラリを使用したクロスコンパイル環境を提供する。同様に、`pkgs.pkgsCross.musl64`はx86_64アーキテクチャ向けの環境を提供する。

### muslライブラリの重要性

ここで注目すべきなのは、両方のターゲットでmuslライブラリを使用している点である。muslは軽量のC標準ライブラリで、静的リンクに適している。これには以下のような利点がある：

1. コンテナイメージのサイズを小さく保てる
2. 依存関係の問題を回避できる（静的リンクのため実行時依存が少ない）
3. 異なる環境での互換性が高い

特にコンテナ環境では、イメージサイズの小ささと依存関係の単純さは重要な利点となる。

### コンテナイメージ生成のプロセス

`dockerTools.buildImage`関数は、Nixの強力な機能を使ってOCI仕様に準拠したコンテナイメージを生成する。この関数は以下の重要な作業を行う：

1. クロスコンパイルされたRustバイナリをイメージに含める
2. 必要なファイル（HTMLファイルなど）をイメージにコピーする
3. 実行コマンドやポート設定などのメタデータを設定する

この過程で、指定されたターゲットアーキテクチャ向けの適切なバイナリとライブラリが自動的に選択される。例えば、x86_64-linux向けのイメージをビルドする場合、含まれるバイナリや依存ライブラリはすべてx86_64-linux用のものになる。

### 開発環境の提供

flake.nixファイルの最後の部分では、開発環境（devShell）も定義されている：

```nix
devShells.aarch64-darwin.default = pkgs.mkShell {
  packages = with pkgs; [ cargo ];
};
```

これにより、開発者は`nix develop`コマンドを使って、必要なツール（この場合はCargo）が揃った開発環境をすぐに立ち上げることができる。これはNixのもう一つの強力な機能であり、プロジェクトの開発環境を宣言的に定義できる点が大きな利点となる。


### コンテナイメージのビルドと実行

上記のプロジェクトを使って実際にコンテナイメージをビルドし、実行する手順を見ていこう。

#### ビルドプロセス

Nixを使ったビルドプロセスは非常にシンプルである。以下のコマンドで異なるアーキテクチャ向けのコンテナイメージを生成できる：

```bash
# ARM64向けイメージのビルド
nix --extra-experimental-features "flakes nix-command" build .#aarch64-container

# x86_64向けイメージのビルド
nix --extra-experimental-features "flakes nix-command" build .#x86_64-container
```

注意点として、`--extra-experimental-features "flakes nix-command"`フラグは、Nixのflakesとnix-command機能がデフォルトで有効になっていない環境で必要となる。これらの機能を常に有効にしたい場合は、`~/.config/nix/nix.conf`に`experimental-features = nix-command flakes`を追加するとよい。

ビルドが完了すると、カレントディレクトリに`result`というシンボリックリンクが作成され、これが生成されたコンテナイメージを指している。このイメージはOCI仕様に準拠したフォーマットで、Docker互換形式で出力されている。

#### Dockerへのロード

生成されたイメージをDockerで使用するには、以下のコマンドでロードする：

```bash
# イメージをDockerにロード
docker load < ./result
```

ロード後、`docker images`コマンドでイメージ一覧を表示すると、新しくロードされたイメージが確認できる。

#### 異なるアーキテクチャでのコンテナ実行

ロードしたイメージを実行する際には、`--platform`フラグを使ってターゲットアーキテクチャを指定する。これにより、macOS上でも異なるアーキテクチャのコンテナを実行できる：

```bash
# ARM64イメージの実行
docker run --platform linux/arm64 -p 7878:7878 web-server:aarch64-unknown-linux-musl

# x86_64イメージの実行
docker run --platform linux/amd64 -p 7878:7878 web-server:x86_64-unknown-linux-musl
```

実行後、ブラウザで`http://localhost:7878`にアクセスすると、サーバーが応答し、HTMLコンテンツが表示される。

#### 開発ワークフローのメリット

この方法の最大の利点は、開発ワークフローの効率性である。従来のQEMUエミュレーションを使ったアプローチと比較して：

1. **ビルド時間の短縮**: エミュレーションのオーバーヘッドがないため、特に複雑なプロジェクトで顕著
2. **リソース効率の向上**: CPUとメモリ使用量が少ない
3. **再現性の確保**: 同じNix設定からは常に同じイメージが生成される
4. **マルチアーキテクチャ対応の単純化**: 同じ設定ファイルで複数アーキテクチャをサポート

Nixによるクロスコンパイルアプローチは、特に頻繁なイテレーションが必要な開発プロセスにおいて、大幅な生産性向上をもたらす。macOSユーザー、特にApple Silicon搭載Macユーザーにとって、この方法はマルチアーキテクチャコンテナ開発のための実用的なソリューションとなる。


## まとめ

この記事では、Nixを使ってmacOS上で直接異なるアーキテクチャ向けのコンテナイメージをクロスコンパイルする方法を紹介した。従来の方法と比較して多くの利点があるこのアプローチを理解し活用することで、開発効率を大幅に向上させることができる。

macOSでのコンテナイメージビルドは、特に異なるアーキテクチャ向けの場合、Docker BuildxなどでQEMUエミュレーションを使用するため遅く非効率である。また、macOSでは仮想化環境をネストして実行することが難しいため、一部の開発シナリオでは技術的制約に直面することがある。

Nixのクロスコンパイル機能を活用することで、これらの問題を解決できる。エミュレーションを使わずに直接異なるアーキテクチャ向けのコンテナイメージをビルドすることで、ビルド時間が大幅に短縮され、リソース使用量も削減される。また、Nixの決定論的なビルドシステムにより、再現性の高いビルドが保証され、キャッシュ機能によって反復的な開発サイクルがさらに効率化される。

この記事で紹介したflake.nixの実装例を使用することで、単純なWebサーバーアプリケーションをmacOS上でaarch64-linuxやx86_64-linux向けにクロスコンパイルし、軽量なコンテナイメージとして構築できる。この手法はmacOSに限らず、x86_64-linux環境からaarch64-linux向けのクロスコンパイルなど、様々な環境組み合わせにも適用可能であり、CI環境での活用も期待できる。

この方法により、特にApple Silicon搭載のMacを使用している開発者は、より効率的にマルチアーキテクチャのコンテナ開発を行うことができるようになる。Nixによるクロスコンパイルアプローチは、仮想化のオーバーヘッドやエミュレーションの遅さに悩まされることなく、高速かつ効率的なコンテナ開発ワークフローを実現できる強力なソリューションである。
